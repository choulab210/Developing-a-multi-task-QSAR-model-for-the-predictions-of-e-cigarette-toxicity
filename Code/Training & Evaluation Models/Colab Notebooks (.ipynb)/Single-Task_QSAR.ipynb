{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOOdV74I91e71LNQSmy2lf8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"YC9ta2lS-FV7","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1753291426667,"user_tz":420,"elapsed":31,"user":{"displayName":"Alexa Canchola","userId":"12486619005608823341"}},"outputId":"131862db-a651-41ae-be64-a6a5f8f39606"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nThis script builds and evaluates a single-task deep neural network QSAR (DNN-QSAR) model for the individual prediction of:\\n - Eye Irritation\\n - Skin Irritation\\n - Skin Sensitization\\n - Carcinogenicity\\n - Genotoxicity\\n\\nThe model is developed for organic compounds associated with e-cigarettes.\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}],"source":["# %% ============================================================================\n","# Single-Task DNN-QSAR Models for prediction of toxicity endpoints\n","# Author: Alexa Canchola, Kunpeng Chen\n","# Advisor: Wei-Chun Chou\n","# Date: July 14, 2025\n","# ==============================================================================\n","\"\"\"\n","This script builds and evaluates a single-task deep neural network QSAR (DNN-QSAR) model for the individual prediction of:\n"," - Eye Irritation\n"," - Skin Irritation\n"," - Skin Sensitization\n"," - Carcinogenicity\n"," - Genotoxicity\n","\n","The model is developed for organic compounds associated with e-cigarettes.\n","\"\"\""]},{"cell_type":"code","source":["# ============================================================================\n","# Install Required Dependencies\n","# ============================================================================\n","!pip install -q rdkit shap scikit-optimize torch torchvision -U"],"metadata":{"id":"fxyCB5-N-GS9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753812157603,"user_tz":420,"elapsed":255516,"user":{"displayName":"Alexa Canchola","userId":"12486619005608823341"}},"outputId":"e91e5d97-6d87-41f5-bf5f-8129315b5ad2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.1 which is incompatible.\n","fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["# %% ============================================================================\n","# Import Required Libraries\n","# ============================================================================\n","# Standard Libraries for Data Handling  & Visualization\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import random, warnings, time\n","from rdkit import RDLogger\n","\n","# Import Required PyTorch Libraries\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# Scikit-learn (sklearn): Model Selection & Evaluation  performance\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.metrics import (accuracy_score, roc_auc_score, balanced_accuracy_score, roc_curve, auc, confusion_matrix,\n","                             matthews_corrcoef, precision_score, recall_score, f1_score)\n","from sklearn.exceptions import UndefinedMetricWarning\n","\n","# Bayesian Optimization (for hyperparameter tuning)\n","from skopt import gp_minimize\n","\n","# RDKit: Molecular Fingerprint & Descriptor Calculations\n","from rdkit import Chem, DataStructs\n","from rdkit.Chem import AllChem, MACCSkeys, RDKFingerprint, Descriptors\n","from rdkit.Chem.AllChem import GetMorganGenerator\n","from rdkit.DataStructs import ConvertToNumpyArray\n","from rdkit.ML.Descriptors import MoleculeDescriptors\n","\n","# Feature Scaling for RDKit Descriptors\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# Applicaibility Domain Calculation\n","from sklearn.preprocessing import RobustScaler\n","from sklearn.decomposition import PCA\n","\n","#Feature Importance analysis\n","import shap\n","\n","#For usage in Google Colab\n","from google.colab import files\n","import pandas as pd\n","import io\n","\n","import joblib\n","import os"],"metadata":{"id":"8vIg2UsP-I1Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================================================================\n","# Filter Extraneous Warnings\n","# ============================================================================\n","warnings.filterwarnings('ignore', category=UserWarning)\n","warnings.filterwarnings('ignore', category=UndefinedMetricWarning)\n","warnings.filterwarnings('ignore', category=RuntimeWarning)\n","RDLogger.DisableLog('rdApp.*') # Disable ALL RDKit logs (Current used to disable extraneous FCFP conversion warnings)"],"metadata":{"id":"Pk1e4uIk-JTp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# %% ============================================================================\n","# Import Data\n","# ============================================================================\n","# Read raw data in Python IDE other than Google Colab\n","# dataset_raw = pd.read_csv('Data_corrected.csv') # Replace with the correct path if needed\n","\n","# Load Data in Google Colab\n","ecig = files.upload() # Data_corrected.csv\n","ecig_file = list(ecig.keys())[0]\n","dataset_raw = pd.read_csv(io.BytesIO(ecig[ecig_file]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":74},"id":"6WxxnpGIVgEt","executionInfo":{"status":"ok","timestamp":1753812214081,"user_tz":420,"elapsed":25070,"user":{"displayName":"Alexa Canchola","userId":"12486619005608823341"}},"outputId":"db5546cf-b414-4243-cf62-34b5cefc6c06"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-665601a0-4cc4-4e37-9680-8c390f9878d8\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-665601a0-4cc4-4e37-9680-8c390f9878d8\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving Data_corrected(1).csv to Data_corrected(1).csv\n"]}]},{"cell_type":"code","source":["# %% ============================================================================\n","# Preprocess Data\n","# ============================================================================\n","column_names = ['Chemicals',\n","                'CAS',\n","                'SMILES',\n","                'Cancer',\n","                'Genotoxicity',\n","                'Eye',\n","                'Skin (Irritating)',\n","                'Skin (sensitizing)']\n","\n","remove_elements = [[],\n","                   [],\n","                   [],\n","                   [],\n","                   [],\n","                   [],\n","                   [],\n","                   [],\n","                   []]\n","# Define Function for Data Cleaning\n","def RemoveElements(df, column_names, remove_elements):\n","    for i in range(0,len(column_names)):\n","        for j in range(0,len(remove_elements[i])):\n","            df = df[df[column_names[i]] != remove_elements[i][j]]\n","\n","    return df\n","\n","data = RemoveElements(dataset_raw, column_names, remove_elements)\n","\n","#Check Data\n","print('Total number of data points: ' + str(len(data.index)))\n","print('--------------------------------------------------------------')\n","print(data.head())"],"metadata":{"id":"Mlqx80uS-UcW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753812219905,"user_tz":420,"elapsed":9,"user":{"displayName":"Alexa Canchola","userId":"12486619005608823341"}},"outputId":"b6d1858f-8145-4c21-96b5-4acc79e76abb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of data points: 966\n","--------------------------------------------------------------\n","                      Chemical_Names        CAS                       SMILES  \\\n","0                     Benzyl acetate   140-11-4          CC(=O)OCC1=CC=CC=C1   \n","1                       Benzophenone   119-61-9  O=C(C1=CC=CC=C1)C1=CC=CC=C1   \n","2                            Acetoin   513-86-0                  CC(O)C(C)=O   \n","3                       alpha-Ionone   127-41-3  CC(=O)\\C=C\\C1C(C)=CCCC1(C)C   \n","4  1,3-Dioxolane, 4-methyl-2-pentyl-  1599-49-1              CCCCCC1OCC(C)O1   \n","\n","  Cancer Genotoxicity Skin Eye Skin (Irritating) Skin (sensitizing)  \n","0      0            1    1   1                 1                  0  \n","1      1            1    0   1                 1                  0  \n","2     na            1    1   1                 1                 na  \n","3     na            1    0   0                 0                  0  \n","4     na           na   na  na                na                 na  \n"]}]},{"cell_type":"code","source":["# ============================================================================\n","#  Check Task Dsitributions\n","# ============================================================================\n","def CheckData(df, column_name):\n","    item_counts = df[column_name].value_counts()\n","\n","    print(\"Item  Count\")\n","    for item, count in item_counts.items():\n","        print(f\"{item}  {count}\")\n","\n","# Check Class Distributions\n","print('--------------------------------------------------------------')\n","print('Class Distributions - Eye irritation')\n","CheckData(data, 'Eye')\n","\n","print('--------------------------------------------------------------')\n","print('Class Distributions - Skin irritation')\n","CheckData(data, 'Skin (Irritating)')\n","\n","print('--------------------------------------------------------------')\n","print('Class Distributions - Skin sensitization')\n","CheckData(data, 'Skin (sensitizing)')\n","\n","print('--------------------------------------------------------------')\n","print('Class Distributions - Cancer')\n","CheckData(data, 'Cancer')\n","\n","print('--------------------------------------------------------------')\n","print('Class Distributions - Genotoxicity')\n","CheckData(data, 'Genotoxicity')"],"metadata":{"id":"mcnNKPHK-VhI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753812336770,"user_tz":420,"elapsed":5,"user":{"displayName":"Alexa Canchola","userId":"12486619005608823341"}},"outputId":"6bcfbd6c-4e4b-4825-b4ea-af1f70b0b7fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------\n","Class Distributions - Eye irritation\n","Item  Count\n","na  611\n","1  253\n","0  102\n","--------------------------------------------------------------\n","Class Distributions - Skin irritation\n","Item  Count\n","na  583\n","1  294\n","0  89\n","--------------------------------------------------------------\n","Class Distributions - Skin sensitization\n","Item  Count\n","na  672\n","0  150\n","1  144\n","--------------------------------------------------------------\n","Class Distributions - Cancer\n","Item  Count\n","na  859\n","1  64\n","0  43\n","--------------------------------------------------------------\n","Class Distributions - Genotoxicity\n","Item  Count\n","na  514\n","1  227\n","0  225\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# Functions for Model Evaluation & Metrics\n","# ============================================================================\n","\n","def weighted_average(values, weights):\n","    # Ensure the lengths of roc_auc_each_output and weights are the same\n","    if len(values) != len(weights):\n","        raise ValueError(\"Length of values must be equal to the length of weights\")\n","\n","    # Calculate the weighted average\n","    weighted_sum = sum(value * weight for value, weight in zip(values, weights))\n","    total_weight = sum(weights)\n","\n","    # Return the weighted average\n","    return weighted_sum / total_weight if total_weight != 0 else 0\n","\n","def model_metrics(y_true, y_pred, y_pred_prob):\n","\n","    if (torch.is_tensor(y_true)):\n","        y_true = y_true.ravel().tolist()\n","    if (torch.is_tensor(y_pred)):\n","        y_pred = y_pred.ravel().tolist()\n","    if (torch.is_tensor(y_pred_prob)):\n","        y_pred_prob = y_pred_prob.ravel().tolist()\n","\n","    roc_auc = roc_auc_score(y_true, y_pred_prob)\n","    balanced_accuracy = balanced_accuracy_score(y_true, y_pred)\n","    mcc = matthews_corrcoef(y_true, y_pred)\n","    accuracy = accuracy_score(y_true, y_pred)\n","    precision = precision_score(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","\n","    return [roc_auc, balanced_accuracy, mcc, accuracy, precision, recall, f1]\n","\n","def calculate_cv_avg_std(outer_results):\n","\n","    # Calculate mean and std of all metrics from outer results\n","    avg_ncv_auc = np.mean([result[\"outer_auc\"] for result in outer_results])\n","    avg_ncv_balanced_acc = np.mean([result[\"outer_balanced_accuracy\"] for result in outer_results])\n","    avg_ncv_mcc = np.mean([result[\"outer_mcc\"] for result in outer_results])\n","    avg_ncv_accuracy = np.mean([result[\"outer_accuracy\"] for result in outer_results])\n","    avg_ncv_precision = np.mean([result[\"outer_precision\"] for result in outer_results])\n","    avg_ncv_recall = np.mean([result[\"outer_recall\"] for result in outer_results])\n","    avg_ncv_f1 = np.mean([result[\"outer_f1\"] for result in outer_results])\n","\n","    std_ncv_auc = np.std([result[\"outer_auc\"] for result in outer_results])\n","    std_ncv_balanced_acc = np.std([result[\"outer_balanced_accuracy\"] for result in outer_results])\n","    std_ncv_mcc = np.std([result[\"outer_mcc\"] for result in outer_results])\n","    std_ncv_accuracy = np.std([result[\"outer_accuracy\"] for result in outer_results])\n","    std_ncv_precision = np.std([result[\"outer_precision\"] for result in outer_results])\n","    std_ncv_recall = np.std([result[\"outer_recall\"] for result in outer_results])\n","    std_ncv_f1 = np.std([result[\"outer_f1\"] for result in outer_results])\n","\n","    # Print the summary of nested cross-validation results\n","    print('----------------------------------------------------------')\n","    print(\"Cross validation (mean ± std):\")\n","    print(\"AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\")\n","\n","    print(f\"{avg_ncv_auc:.3f} ± {std_ncv_auc:.3f}, {avg_ncv_balanced_acc:.3f} ± {std_ncv_balanced_acc:.3f}, {avg_ncv_mcc:.3f} ± {std_ncv_mcc:.3f}, \"\n","          f\"{avg_ncv_accuracy:.3f} ± {std_ncv_accuracy:.3f}, {avg_ncv_precision:.3f} ± {std_ncv_precision:.3f}, \"\n","          f\"{avg_ncv_recall:.3f} ± {std_ncv_recall:.3f}, {avg_ncv_f1:.3f} ± {std_ncv_f1:.3f}\")\n","\n","    return avg_ncv_auc, avg_ncv_f1, avg_ncv_balanced_acc, avg_ncv_mcc, std_ncv_mcc"],"metadata":{"id":"JH20faZ7-boU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================================================================\n","# Generate desired fingerprints/molecular descriptors from SMILES\n","# ============================================================================\n","\n","def smiles_to_feature(smiles, mode=\"MACCS\", **kwargs):\n","    mol = Chem.MolFromSmiles(smiles)\n","    if mol is None:\n","        if mode == \"MACCS\":\n","            return np.zeros(167, dtype=int)\n","        elif mode in [\"Morgan\", \"FCFP\", \"RDK\"]:\n","            fpSize = kwargs.get(\"fpSize\", 2048)\n","            return np.zeros(fpSize, dtype=int)\n","        elif mode == \"Descriptors\":\n","            desc_list = [desc[0] for desc in Descriptors._descList]\n","            return np.zeros(len(desc_list))\n","        else:\n","            raise ValueError(f\"Unknown mode: {mode}\")\n","\n","    if mode == \"MACCS\":\n","        fp = MACCSkeys.GenMACCSKeys(mol)\n","        arr = np.zeros((167,), dtype=int)\n","        ConvertToNumpyArray(fp, arr)\n","        return arr\n","\n","    elif mode == \"Morgan\":\n","        radius = kwargs.get(\"radius\", 3)\n","        fpSize = kwargs.get(\"fpSize\", 2048)\n","        generator = AllChem.GetMorganGenerator(radius=radius, fpSize=fpSize)\n","        fp = generator.GetFingerprint(mol)\n","        return np.array(fp)\n","\n","    elif mode == \"FCFP\": #Note: This method uses a deprecated version to generate FCFP that will be removed in future versions of RDKit\n","        radius = kwargs.get(\"radius\", 3)\n","        fpSize = kwargs.get(\"fpSize\", 2048)\n","        include_chirality = kwargs.get(\"include_chirality\", False)\n","        invariants = AllChem.GetFeatureInvariants(mol)\n","        fp = AllChem.GetMorganFingerprintAsBitVect(\n","            mol, radius, nBits=fpSize, invariants=invariants, useChirality=include_chirality\n","        )\n","        arr = np.zeros(fpSize, dtype=int)\n","        ConvertToNumpyArray(fp, arr)\n","        return arr\n","\n","    elif mode == \"RDK\":\n","        fpSize = kwargs.get(\"fpSize\", 2048)\n","        fp = RDKFingerprint(mol, fpSize=fpSize)\n","        arr = np.zeros(fpSize, dtype=int)\n","        ConvertToNumpyArray(fp, arr)\n","        return arr\n","\n","    elif mode == \"Descriptors\":\n","        desc_list = [desc[0] for desc in Descriptors._descList]\n","        calc = MoleculeDescriptors.MolecularDescriptorCalculator(desc_list)\n","        mol = Chem.AddHs(mol)\n","        descriptors = calc.CalcDescriptors(mol)\n","        return np.array(descriptors)\n","\n","    else:\n","        raise ValueError(f\"Unknown mode: {mode}\")\n","\n","smiles_list = data['SMILES'].tolist()\n","\n","# Choose mode: \"MACCS\", \"Morgan\", \"FCFP\", \"RDK\", or \"Descriptors\"\n","mode = \"MACCS\"\n","\n","X = np.array([smiles_to_feature(smiles, mode=mode) for smiles in smiles_list])\n","\n","if mode == \"Descriptors\":\n","    desc_names = [\"RDKit_\" + desc[0] for desc in Descriptors._descList]\n","    X_df = pd.DataFrame(X, columns=desc_names)\n","    X_df = X_df.replace([np.inf, -np.inf], np.nan).fillna(0) # Replace inf and NaN, then scale to range of 0,1\n","    scaler = MinMaxScaler()\n","    X_scaled = scaler.fit_transform(X_df)\n","    X_df = pd.DataFrame(X_scaled, columns=X_df.columns)\n","else:\n","    X_df = pd.DataFrame(X, columns=[f'FP_{i}' for i in range(X.shape[1])])\n","\n","print(X_df)"],"metadata":{"id":"T4JRlUTo-l4v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753812346444,"user_tz":420,"elapsed":1550,"user":{"displayName":"Alexa Canchola","userId":"12486619005608823341"}},"outputId":"e6bc1822-4c0b-436e-b640-c19f5283b1ee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["     FP_0  FP_1  FP_2  FP_3  FP_4  FP_5  FP_6  FP_7  FP_8  FP_9  ...  FP_157  \\\n","0       0     0     0     0     0     0     0     0     0     0  ...       1   \n","1       0     0     0     0     0     0     0     0     0     0  ...       0   \n","2       0     0     0     0     0     0     0     0     0     0  ...       1   \n","3       0     0     0     0     0     0     0     0     0     0  ...       0   \n","4       0     0     0     0     0     0     0     0     0     0  ...       1   \n","..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...     ...   \n","961     0     0     0     0     0     0     0     0     0     0  ...       1   \n","962     0     0     0     0     0     0     0     0     0     0  ...       1   \n","963     0     0     0     0     0     0     0     0     0     0  ...       1   \n","964     0     0     0     0     0     0     0     0     0     0  ...       1   \n","965     0     0     0     0     0     0     0     0     0     0  ...       1   \n","\n","     FP_158  FP_159  FP_160  FP_161  FP_162  FP_163  FP_164  FP_165  FP_166  \n","0         0       1       1       0       1       1       1       1       0  \n","1         0       0       0       0       1       1       1       1       0  \n","2         0       1       1       0       0       0       1       0       0  \n","3         0       0       1       0       0       1       1       1       0  \n","4         0       1       1       0       0       0       1       1       0  \n","..      ...     ...     ...     ...     ...     ...     ...     ...     ...  \n","961       0       1       1       0       0       0       1       0       0  \n","962       0       1       1       0       1       0       1       1       0  \n","963       1       1       1       1       1       1       1       1       0  \n","964       0       1       1       0       0       1       1       1       0  \n","965       0       1       1       0       0       0       1       0       0  \n","\n","[966 rows x 167 columns]\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# Functions to Convert Dataframes to PyTorch Tensors\n","# ============================================================================\n","def convert_to_X_tensors(X_train, X_test):\n","    X_train_np = X_train.to_numpy()\n","    X_test_np = X_test.to_numpy()\n","\n","    X_train_tensor = torch.tensor(X_train_np, dtype=torch.float32)\n","    X_test_tensor = torch.tensor(X_test_np, dtype=torch.float32)\n","\n","    return X_train_tensor, X_test_tensor\n","\n","def convert_to_Y_tensors(Y_train, Y_test):\n","    Y_train_np = Y_train.to_numpy()\n","    Y_train_np = np.where(pd.isnull(Y_train_np), np.nan, Y_train_np)\n","\n","    Y_test_np = Y_test.to_numpy()\n","    Y_test_np = np.where(pd.isnull(Y_test_np), np.nan, Y_test_np)\n","\n","    Y_train_tensor = torch.tensor(Y_train_np, dtype=torch.float32)\n","    Y_test_tensor = torch.tensor(Y_test_np, dtype=torch.float32)\n","\n","    print(Y_train_tensor.shape)\n","    print(Y_test_tensor.shape)\n","\n","    return Y_train_tensor, Y_test_tensor"],"metadata":{"id":"ScJD6Ly2-8Cp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================================================================\n","# Neural Network Definition and Cross-Validation Training Function\n","# ============================================================================\n","seed = 42\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","\n","class NeuralNetwork(nn.Module):\n","    def __init__(self, input_size, shared_layer_sizes, output_layer_sizes, specific_layer_sizes):\n","        super(NeuralNetwork, self).__init__()\n","        self.shared_layers = nn.ModuleList()\n","        self.shared_layers.append(nn.Linear(input_size, shared_layer_sizes[0]))\n","        for i in range(len(shared_layer_sizes) - 1):\n","            self.shared_layers.append(nn.Linear(shared_layer_sizes[i], shared_layer_sizes[i + 1]))\n","        self.output_layers = nn.ModuleList()\n","        for output_size in output_layer_sizes:\n","            specific_layers = nn.Sequential(\n","                nn.Linear(shared_layer_sizes[-1], specific_layer_sizes[0]),\n","                nn.ReLU(),\n","                nn.Linear(specific_layer_sizes[0], output_size)\n","            )\n","            self.output_layers.append(specific_layers)\n","\n","    def forward(self, x):\n","        for layer in self.shared_layers:\n","            x = torch.relu(layer(x))\n","        outputs = [output_layer(x) for output_layer in self.output_layers]\n","        outputs = [torch.sigmoid(output_layer(x)) for output_layer in self.output_layers]\n","        return outputs\n","\n","# Modify the train_model function to integrate SMOTE\n","def train_model(X, Y, learning_rate, epochs, batch_size, shared_layer_sizes, output_layer_sizes, specific_layer_sizes, patience, l2_strength):\n","\n","    # Use KFold for multilabel tasks\n","    kf = KFold(n_splits=5)#, shuffle=True, random_state=42)\n","    best_model = None\n","    best_f1_score = 0\n","    best_balanced_acc = 0\n","    best_auc = 0\n","    best_mcc = 0\n","    outer_results = []\n","\n","    for train_index, val_index in kf.split(X, Y):  # Stratified split based on labels Y_filtered\n","        X_train, X_val = X[train_index], X[val_index]\n","        Y_train, Y_val = Y[train_index], Y[val_index]\n","\n","        model = NeuralNetwork(input_size=X.shape[1], shared_layer_sizes=shared_layer_sizes, output_layer_sizes=output_layer_sizes, specific_layer_sizes=specific_layer_sizes)\n","        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","        epochs_without_improvement = 0\n","        for epoch in range(epochs):\n","            model.train()\n","            for i in range(0, len(X_train), batch_size):\n","                X_batch = X_train[i:i + batch_size]\n","                Y_batch = Y_train[i:i + batch_size]\n","                optimizer.zero_grad()\n","                outputs = model(X_batch)\n","\n","                losses = []\n","                for j, output in enumerate(outputs):\n","                    mask = ~torch.isnan(Y_batch[:, j])  # Create mask for valid labels\n","                    if mask.sum() > 0:\n","                        valid_output = output.squeeze(1)[mask]\n","                        valid_targets = Y_batch[:, j][mask]\n","                        loss = nn.BCELoss()(valid_output, valid_targets)\n","                        losses.append(loss)\n","\n","                if losses:  # Avoid zero loss if all values are NaN\n","                    total_loss = sum(losses)\n","\n","                    # L2 Regularization\n","                    l2_loss = sum(torch.norm(param, 2) for param in model.parameters())\n","                    total_loss += l2_strength * l2_loss  # Add L2 loss to the total loss\n","\n","                    total_loss.backward()\n","                    optimizer.step()\n","\n","            # Validation\n","            model.eval()\n","            with torch.no_grad():\n","                val_true_labels = Y_val.numpy()\n","                val_pred_probs_list = model(X_val)\n","                val_pred_list = [torch.where(output > 0.5, torch.tensor(1.0), torch.tensor(0.0)) for output in val_pred_probs_list]\n","\n","                val_pred_probs = torch.stack(val_pred_probs_list, dim=1)  # Stack all outputs\n","                val_pred = torch.stack(val_pred_list, dim=1)  # Stack all outputs\n","\n","                roc_auc_each_output = []\n","                balanced_acc_each_output = []\n","                mcc_each_output = []\n","                accuracy_each_output = []\n","                precision_each_output = []\n","                recall_each_output = []\n","                f1_score_each_output = []\n","\n","                for j in range(val_pred_probs.shape[1]):  # Iterate over each task (column)\n","\n","                    valid_mask = ~np.isnan(val_true_labels[:, j])  # Mask to filter out NaN values\n","                    valid_true_labels = val_true_labels[valid_mask, j]\n","                    val_pred_task = val_pred[valid_mask, j].numpy()\n","                    val_pred_probs_task = val_pred_probs[valid_mask, j].numpy()\n","\n","                    if valid_mask.sum() > 0:\n","\n","                        results = model_metrics(valid_true_labels, val_pred_task, val_pred_probs_task)\n","\n","                        # Calculate AUC if there are both positive and negative samples\n","                        if np.sum(valid_true_labels) > 0 and np.sum(valid_true_labels) < len(valid_true_labels):\n","                            roc_auc_each_output.append(results[0])\n","                        else:\n","                            roc_auc_each_output.append(0.5)  # Typically represents a random guess\n","\n","                        balanced_acc_each_output.append(results[1])\n","                        mcc_each_output.append(results[2])\n","                        accuracy_each_output.append(results[3])\n","                        precision_each_output.append(results[4])\n","                        recall_each_output.append(results[5])\n","                        f1_score_each_output.append(results[6])\n","\n","            # Calculate average metrics of the outputs\n","            '''\n","            roc_auc = harmonic_mean(roc_auc_each_output)\n","            balanced_acc = harmonic_mean(balanced_acc_each_output)\n","            mcc = harmonic_mean(mcc_each_output)\n","            accuracy = harmonic_mean(accuracy_each_output)\n","            precision = harmonic_mean(precision_each_output)\n","            recall = harmonic_mean(recall_each_output)\n","            f1_score = harmonic_mean(f1_score_each_output)\n","            #'''\n","\n","            '''\n","            roc_auc = np.mean(roc_auc_each_output)\n","            balanced_acc = np.mean(balanced_acc_each_output)\n","            mcc = np.mean(mcc_each_output)\n","            accuracy = np.mean(accuracy_each_output)\n","            precision = np.mean(precision_each_output)\n","            recall = np.mean(recall_each_output)\n","            f1_score = np.mean(f1_score_each_output)\n","            #'''\n","\n","            #'''\n","            weights = [1.0]\n","            roc_auc = weighted_average(roc_auc_each_output, weights)\n","            balanced_acc = weighted_average(balanced_acc_each_output, weights)\n","            mcc = weighted_average(mcc_each_output, weights)\n","            accuracy = weighted_average(accuracy_each_output, weights)\n","            precision = weighted_average(precision_each_output, weights)\n","            recall = weighted_average(recall_each_output, weights)\n","            f1_score = weighted_average(f1_score_each_output, weights)\n","            #'''\n","\n","            # Append the outer results\n","            outer_results.append({\n","                \"outer_auc\": roc_auc,\n","                \"outer_balanced_accuracy\": balanced_acc,\n","                \"outer_mcc\": mcc,\n","                \"outer_accuracy\": accuracy,\n","                \"outer_precision\": precision,\n","                \"outer_recall\": recall,\n","                \"outer_f1\": f1_score,\n","            })\n","\n","            if f1_score >= best_f1_score:\n","                best_f1_score = f1_score\n","                best_balanced_acc = balanced_acc\n","                best_auc = roc_auc\n","                best_mcc = mcc\n","                best_model = model\n","                epochs_without_improvement = 0\n","            else:\n","                epochs_without_improvement += 1\n","\n","            # Check for early stopping after evaluating all tasks\n","            if epochs_without_improvement >= patience:\n","                break\n","\n","    # Calculate mean and standard deviation of the metrics over all folds\n","\n","    ave_auc, ave_f1, ave_balanced_acc, avg_ncv_mcc, std_ncv_mcc = calculate_cv_avg_std(outer_results)\n","\n","    if (std_ncv_mcc > avg_ncv_mcc) | (avg_ncv_mcc <= 0.0):\n","        return 0.00\n","    else:\n","        return ave_auc"],"metadata":{"id":"U0DzfP9Y-_qY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ============================================================================\n","# Prepare Target Variables (Y)\n","# ============================================================================\n","task_names = ['Genotoxicity'] # IMPORTANT: Change to Desired Task Here!\n","Y1 = data[task_names].copy()\n","\n","# Replace 'na' with NaN and convert to numeric\n","Y1 = Y1.replace('na', np.nan)\n","for col in task_names:\n","    Y1[col] = pd.to_numeric(Y1[col])\n","Y1_df = pd.DataFrame(Y1, columns=task_names)\n","\n","# Convert Y back to numpy array\n","Y1 = Y1_df.values\n","\n","print(Y1_df)\n","\n","X1_clean_df = X_df.loc[Y1_df.dropna(thresh=1).index] # thresh=3\n","Y1_clean_df = Y1_df.dropna(thresh=1)\n","print(X1_clean_df.shape)\n","print(Y1_clean_df.shape)"],"metadata":{"id":"Ig698JnS_F_X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753812362219,"user_tz":420,"elapsed":23,"user":{"displayName":"Alexa Canchola","userId":"12486619005608823341"}},"outputId":"b3c026af-3dde-4b3c-e324-6158f71ab846"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["     Genotoxicity\n","0             1.0\n","1             1.0\n","2             1.0\n","3             1.0\n","4             NaN\n","..            ...\n","961           NaN\n","962           NaN\n","963           NaN\n","964           NaN\n","965           NaN\n","\n","[966 rows x 1 columns]\n","(452, 167)\n","(452, 1)\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# Split the Dataset into Training and Test Sets\n","# ============================================================================\n","\n","X1_train, X1_test, Y1_train, Y1_test = train_test_split(X1_clean_df, Y1_clean_df, test_size=0.2, random_state=42)\n","\n","print('--------------------------------------------------------------')\n","CheckData(Y1_train, 'Genotoxicity') # Change to Desired Task\n","print('-------------------------------------------------------------')\n","CheckData(Y1_test, 'Genotoxicity')# Change to Desired Task"],"metadata":{"id":"UwrGClMl_VaQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753812364700,"user_tz":420,"elapsed":19,"user":{"displayName":"Alexa Canchola","userId":"12486619005608823341"}},"outputId":"5034402d-efbc-4ffd-9678-99be3b898418"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------\n","Item  Count\n","0.0  182\n","1.0  179\n","-------------------------------------------------------------\n","Item  Count\n","1.0  48\n","0.0  43\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# Apply Random Oversampling to Training Dataset to Reach Target Size\n","# ============================================================================\n","\n","# Desired total number of training samples\n","target_size = 1268\n","\n","current_size = len(X1_train) # Current training size\n","num_extra = target_size - current_size # Number of additional samples needed\n","\n","# Randomly sample (with replacement) from existing data\n","np.random.seed(42)\n","resample_indices = np.random.choice(current_size, size=num_extra, replace=True)\n","\n","# Create the new samples & combine with new\n","X_extra = X1_train.iloc[resample_indices]\n","Y_extra = Y1_train.iloc[resample_indices]\n","X_combined = pd.concat([X1_train, X_extra], axis=0).reset_index(drop=True)\n","Y_combined = pd.concat([Y1_train, Y_extra], axis=0).reset_index(drop=True)\n","\n","# Shuffle both DataFrames in unison\n","shuffled_indices = np.random.permutation(target_size)\n","X_train_resampled = X_combined.iloc[shuffled_indices].reset_index(drop=True)\n","Y1_train_resampled = Y_combined.iloc[shuffled_indices].reset_index(drop=True)\n","\n","# Check\n","print(X_train_resampled.shape)  # Should be (1268, n_features)\n","print(Y1_train_resampled.shape) # Should be (1268, 3)"],"metadata":{"id":"jGcDScFqAK7K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753812367632,"user_tz":420,"elapsed":26,"user":{"displayName":"Alexa Canchola","userId":"12486619005608823341"}},"outputId":"868802b3-b87e-4a40-d6b3-e2c5f3aaac5b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(1268, 167)\n","(1268, 1)\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# Convert Resampled Datasets to Pytorch Tensors\n","# ============================================================================\n","X1_train_tensor, X1_test_tensor = convert_to_X_tensors(X_train_resampled, X1_test)\n","Y1_train_tensor, Y1_test_tensor = convert_to_Y_tensors(Y1_train_resampled, Y1_test)"],"metadata":{"id":"bh7cxaxsAQp6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753812369570,"user_tz":420,"elapsed":20,"user":{"displayName":"Alexa Canchola","userId":"12486619005608823341"}},"outputId":"55232287-018e-4d9d-a905-ab73bb7c9c8c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1268, 1])\n","torch.Size([91, 1])\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# Bayesian Hyperparameter Optimization Using gp_minimize (AUC Objective)\n","# ============================================================================\n","start_time = time.time() # OPTIONAL: Track time elapsed to train model\n","\n","# Objective function for gp_minimize\n","def objective1(params):\n","    learning_rate, batch_size, epochs, shared_layer_size, specific_layer_size, l2_strength = params\n","\n","    best_auc = train_model(\n","        X1_train_tensor,\n","        Y1_train_tensor,\n","        learning_rate,\n","        epochs,\n","        batch_size,\n","        [shared_layer_size],\n","        [1],\n","        [specific_layer_size],\n","        patience=20,\n","        l2_strength=l2_strength  # Pass L2 strength to the train_model\n","    )\n","    print('----------------------------------------------------------')\n","    print(f\"Best AUC: {best_auc:.3f}\")\n","    opt_criteria = float(best_auc) * (-1)\n","\n","    return opt_criteria  # Minimize the negative AUC\n","\n","# Define the search space\n","search_space = [\n","    (1e-4, 1e-1),    # Learning rate\n","    (21, 37),         # Batch size\n","    (30, 80),        # Epochs\n","    (64, 256),      # Shared layer size\n","    (32, 125),       # Specific layer size\n","    (1e-4, 1e-2)     # L2 regularization strength\n","]\n","\n","class CallIndexPrinter:\n","    def __init__(self):\n","        self.index = 1\n","\n","    def __call__(self, res):\n","        print(f\"Call index {self.index} finished.\")\n","        self.index += 1\n","\n","print('Start training:')\n","\n","# Create an instance of the CallIndexPrinter\n","call_index_printer = CallIndexPrinter()\n","\n","# Perform Bayesian optimization with the callback\n","results = gp_minimize(objective1, search_space, n_calls=40, random_state=seed, callback=[call_index_printer])\n","\n","# Print the best parameters\n","best_params = results.x\n","best_auc = -results.fun\n","\n","print(\"Best hyperparameters: Learning Rate: {:.5f}, Batch Size: {}, Epochs: {}, Shared Layer Size: {}, Specific Layer Size: {}, L2 regularization strength: {}\".format(\n","    best_params[0], best_params[1], best_params[2], best_params[3], best_params[4], best_params[5]\n","))\n","print(\"Best AUC: {:.3f}\".format(best_auc))\n","\n","end_time = time.time()\n","print(f\"Elapsed Time: {end_time - start_time:.2f} seconds\")\n"],"metadata":{"id":"cWEBDY-5AUHb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753813470644,"user_tz":420,"elapsed":1100192,"user":{"displayName":"Alexa Canchola","userId":"12486619005608823341"}},"outputId":"fd69ea0f-ce8c-4acf-e673-cb39a8f3e2a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Start training:\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.897 ± 0.067, 0.820 ± 0.067, 0.654 ± 0.121, 0.821 ± 0.068, 0.869 ± 0.085, 0.780 ± 0.119, 0.812 ± 0.074\n","----------------------------------------------------------\n","Best AUC: 0.897\n","Call index 1 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.920 ± 0.042, 0.839 ± 0.047, 0.687 ± 0.092, 0.840 ± 0.047, 0.880 ± 0.070, 0.799 ± 0.080, 0.833 ± 0.048\n","----------------------------------------------------------\n","Best AUC: 0.920\n","Call index 2 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.755 ± 0.152, 0.693 ± 0.132, 0.417 ± 0.265, 0.697 ± 0.126, 0.732 ± 0.171, 0.827 ± 0.183, 0.738 ± 0.075\n","----------------------------------------------------------\n","Best AUC: 0.755\n","Call index 3 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.965 ± 0.045, 0.917 ± 0.056, 0.835 ± 0.112, 0.917 ± 0.057, 0.927 ± 0.054, 0.907 ± 0.070, 0.916 ± 0.058\n","----------------------------------------------------------\n","Best AUC: 0.965\n","Call index 4 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.959 ± 0.040, 0.902 ± 0.051, 0.807 ± 0.100, 0.902 ± 0.051, 0.915 ± 0.042, 0.889 ± 0.079, 0.900 ± 0.054\n","----------------------------------------------------------\n","Best AUC: 0.959\n","Call index 5 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.915 ± 0.044, 0.834 ± 0.046, 0.682 ± 0.089, 0.833 ± 0.046, 0.903 ± 0.071, 0.759 ± 0.084, 0.820 ± 0.047\n","----------------------------------------------------------\n","Best AUC: 0.915\n","Call index 6 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.948 ± 0.048, 0.891 ± 0.054, 0.783 ± 0.106, 0.890 ± 0.054, 0.905 ± 0.054, 0.876 ± 0.078, 0.889 ± 0.058\n","----------------------------------------------------------\n","Best AUC: 0.948\n","Call index 7 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.959 ± 0.040, 0.894 ± 0.051, 0.793 ± 0.098, 0.895 ± 0.051, 0.911 ± 0.046, 0.879 ± 0.085, 0.892 ± 0.056\n","----------------------------------------------------------\n","Best AUC: 0.959\n","Call index 8 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.890 ± 0.037, 0.808 ± 0.049, 0.630 ± 0.097, 0.808 ± 0.049, 0.875 ± 0.084, 0.741 ± 0.084, 0.796 ± 0.049\n","----------------------------------------------------------\n","Best AUC: 0.890\n","Call index 9 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.876 ± 0.039, 0.794 ± 0.048, 0.608 ± 0.093, 0.795 ± 0.047, 0.867 ± 0.092, 0.726 ± 0.099, 0.781 ± 0.053\n","----------------------------------------------------------\n","Best AUC: 0.876\n","Call index 10 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.939 ± 0.045, 0.872 ± 0.049, 0.748 ± 0.095, 0.872 ± 0.049, 0.895 ± 0.045, 0.846 ± 0.085, 0.867 ± 0.054\n","----------------------------------------------------------\n","Best AUC: 0.939\n","Call index 11 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.950 ± 0.036, 0.888 ± 0.048, 0.778 ± 0.095, 0.888 ± 0.048, 0.896 ± 0.047, 0.883 ± 0.078, 0.888 ± 0.052\n","----------------------------------------------------------\n","Best AUC: 0.950\n","Call index 12 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.968 ± 0.037, 0.916 ± 0.047, 0.834 ± 0.092, 0.916 ± 0.047, 0.926 ± 0.044, 0.907 ± 0.063, 0.915 ± 0.049\n","----------------------------------------------------------\n","Best AUC: 0.968\n","Call index 13 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.820 ± 0.060, 0.750 ± 0.075, 0.505 ± 0.142, 0.749 ± 0.076, 0.779 ± 0.089, 0.701 ± 0.165, 0.726 ± 0.144\n","----------------------------------------------------------\n","Best AUC: 0.820\n","Call index 14 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.804 ± 0.049, 0.717 ± 0.076, 0.444 ± 0.139, 0.717 ± 0.078, 0.748 ± 0.134, 0.651 ± 0.209, 0.673 ± 0.186\n","----------------------------------------------------------\n","Best AUC: 0.804\n","Call index 15 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.818 ± 0.057, 0.745 ± 0.063, 0.495 ± 0.119, 0.744 ± 0.065, 0.760 ± 0.086, 0.712 ± 0.143, 0.729 ± 0.116\n","----------------------------------------------------------\n","Best AUC: 0.818\n","Call index 16 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.958 ± 0.041, 0.902 ± 0.052, 0.805 ± 0.103, 0.902 ± 0.052, 0.915 ± 0.053, 0.890 ± 0.068, 0.901 ± 0.054\n","----------------------------------------------------------\n","Best AUC: 0.958\n","Call index 17 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.959 ± 0.041, 0.902 ± 0.056, 0.806 ± 0.109, 0.902 ± 0.056, 0.913 ± 0.043, 0.891 ± 0.092, 0.899 ± 0.061\n","----------------------------------------------------------\n","Best AUC: 0.959\n","Call index 18 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.954 ± 0.040, 0.891 ± 0.050, 0.787 ± 0.096, 0.892 ± 0.050, 0.913 ± 0.048, 0.870 ± 0.082, 0.889 ± 0.055\n","----------------------------------------------------------\n","Best AUC: 0.954\n","Call index 19 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.951 ± 0.040, 0.888 ± 0.049, 0.779 ± 0.095, 0.888 ± 0.049, 0.904 ± 0.050, 0.871 ± 0.079, 0.885 ± 0.051\n","----------------------------------------------------------\n","Best AUC: 0.951\n","Call index 20 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.967 ± 0.035, 0.916 ± 0.048, 0.835 ± 0.093, 0.917 ± 0.048, 0.922 ± 0.042, 0.912 ± 0.072, 0.916 ± 0.050\n","----------------------------------------------------------\n","Best AUC: 0.967\n","Call index 21 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.961 ± 0.039, 0.909 ± 0.052, 0.819 ± 0.101, 0.909 ± 0.052, 0.916 ± 0.044, 0.903 ± 0.076, 0.908 ± 0.054\n","----------------------------------------------------------\n","Best AUC: 0.961\n","Call index 22 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.959 ± 0.038, 0.905 ± 0.050, 0.813 ± 0.098, 0.905 ± 0.050, 0.915 ± 0.044, 0.897 ± 0.076, 0.905 ± 0.053\n","----------------------------------------------------------\n","Best AUC: 0.959\n","Call index 23 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.762 ± 0.044, 0.687 ± 0.067, 0.385 ± 0.121, 0.685 ± 0.072, 0.727 ± 0.103, 0.640 ± 0.182, 0.657 ± 0.145\n","----------------------------------------------------------\n","Best AUC: 0.762\n","Call index 24 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.904 ± 0.044, 0.820 ± 0.053, 0.653 ± 0.101, 0.819 ± 0.053, 0.868 ± 0.080, 0.775 ± 0.112, 0.810 ± 0.060\n","----------------------------------------------------------\n","Best AUC: 0.904\n","Call index 25 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.952 ± 0.040, 0.886 ± 0.049, 0.776 ± 0.096, 0.886 ± 0.049, 0.907 ± 0.047, 0.866 ± 0.080, 0.884 ± 0.053\n","----------------------------------------------------------\n","Best AUC: 0.952\n","Call index 26 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.971 ± 0.034, 0.921 ± 0.047, 0.844 ± 0.092, 0.921 ± 0.047, 0.930 ± 0.038, 0.913 ± 0.068, 0.920 ± 0.049\n","----------------------------------------------------------\n","Best AUC: 0.971\n","Call index 27 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.949 ± 0.040, 0.879 ± 0.048, 0.766 ± 0.091, 0.880 ± 0.048, 0.917 ± 0.047, 0.840 ± 0.092, 0.873 ± 0.056\n","----------------------------------------------------------\n","Best AUC: 0.949\n","Call index 28 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.946 ± 0.042, 0.874 ± 0.049, 0.753 ± 0.095, 0.874 ± 0.049, 0.888 ± 0.052, 0.861 ± 0.089, 0.872 ± 0.055\n","----------------------------------------------------------\n","Best AUC: 0.946\n","Call index 29 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.953 ± 0.047, 0.894 ± 0.055, 0.791 ± 0.108, 0.894 ± 0.055, 0.906 ± 0.045, 0.882 ± 0.085, 0.892 ± 0.059\n","----------------------------------------------------------\n","Best AUC: 0.953\n","Call index 30 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.943 ± 0.041, 0.875 ± 0.049, 0.754 ± 0.095, 0.875 ± 0.049, 0.899 ± 0.047, 0.849 ± 0.081, 0.871 ± 0.053\n","----------------------------------------------------------\n","Best AUC: 0.943\n","Call index 31 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.967 ± 0.037, 0.914 ± 0.048, 0.831 ± 0.094, 0.914 ± 0.049, 0.926 ± 0.045, 0.903 ± 0.072, 0.913 ± 0.051\n","----------------------------------------------------------\n","Best AUC: 0.967\n","Call index 32 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.960 ± 0.041, 0.903 ± 0.051, 0.808 ± 0.101, 0.903 ± 0.051, 0.916 ± 0.044, 0.888 ± 0.077, 0.901 ± 0.053\n","----------------------------------------------------------\n","Best AUC: 0.960\n","Call index 33 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.924 ± 0.047, 0.846 ± 0.055, 0.698 ± 0.108, 0.845 ± 0.055, 0.889 ± 0.067, 0.799 ± 0.081, 0.838 ± 0.057\n","----------------------------------------------------------\n","Best AUC: 0.924\n","Call index 34 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.966 ± 0.037, 0.914 ± 0.048, 0.831 ± 0.094, 0.915 ± 0.048, 0.927 ± 0.046, 0.903 ± 0.070, 0.913 ± 0.051\n","----------------------------------------------------------\n","Best AUC: 0.966\n","Call index 35 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.963 ± 0.040, 0.905 ± 0.052, 0.814 ± 0.101, 0.906 ± 0.052, 0.916 ± 0.041, 0.894 ± 0.086, 0.903 ± 0.056\n","----------------------------------------------------------\n","Best AUC: 0.963\n","Call index 36 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.931 ± 0.044, 0.855 ± 0.050, 0.719 ± 0.097, 0.856 ± 0.051, 0.881 ± 0.058, 0.833 ± 0.102, 0.851 ± 0.058\n","----------------------------------------------------------\n","Best AUC: 0.931\n","Call index 37 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.915 ± 0.044, 0.833 ± 0.049, 0.681 ± 0.090, 0.832 ± 0.048, 0.886 ± 0.078, 0.782 ± 0.116, 0.821 ± 0.053\n","----------------------------------------------------------\n","Best AUC: 0.915\n","Call index 38 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.965 ± 0.039, 0.915 ± 0.049, 0.832 ± 0.097, 0.915 ± 0.049, 0.928 ± 0.043, 0.902 ± 0.072, 0.913 ± 0.052\n","----------------------------------------------------------\n","Best AUC: 0.965\n","Call index 39 finished.\n","----------------------------------------------------------\n","Cross validation (mean ± std):\n","AUC, balanced accuracy, MCC, accuracy, precision, recall, F1\n","0.944 ± 0.042, 0.875 ± 0.050, 0.755 ± 0.095, 0.875 ± 0.050, 0.907 ± 0.044, 0.841 ± 0.091, 0.870 ± 0.058\n","----------------------------------------------------------\n","Best AUC: 0.944\n","Call index 40 finished.\n","Best hyperparameters: Learning Rate: 0.00336, Batch Size: 21, Epochs: 66, Shared Layer Size: 256, Specific Layer Size: 64, L2 regularization strength: 0.0012999668286582144\n","Best AUC: 0.971\n","Elapsed Time: 1100.19 seconds\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# Final Training of Best Neural Network Model and Evaluation on Training Data\n","# ============================================================================\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","\n","best_model = NeuralNetwork(\n","    input_size=X1_train_tensor.shape[1],\n","    shared_layer_sizes=[best_params[3]],  # Two shared layers\n","    output_layer_sizes=[1],  # Output sizes\n","    specific_layer_sizes=[best_params[4]]  # Specific layer sizes\n",")\n","\n","optimizer = optim.Adam(best_model.parameters(), lr=best_params[0])\n","best_model.train()\n","\n","# Training loop\n","for epoch in range(best_params[2]):  # Use the best number of epochs\n","    for i in range(0, len(X1_train_tensor), best_params[1]):  # Use the best batch size\n","        X1_batch = X1_train_tensor[i:i + best_params[1]]\n","        Y1_batch = Y1_train_tensor[i:i + best_params[1]]\n","        optimizer.zero_grad()\n","        outputs = best_model(X1_batch)\n","\n","        losses = []\n","        for j, output in enumerate(outputs):\n","            mask = ~torch.isnan(Y1_batch[:, j])  # Create mask for valid labels\n","            if mask.sum() > 0:\n","                valid_output = output.squeeze(1)[mask]\n","                valid_targets = Y1_batch[:, j][mask]\n","                loss = nn.BCELoss()(valid_output, valid_targets)\n","                losses.append(loss)\n","\n","        if losses:\n","            total_loss = sum(losses)\n","\n","            # L2 Regularization\n","            l2_loss = sum(torch.norm(param, 2) for param in best_model.parameters())\n","            total_loss += best_params[5] * l2_loss  # Add L2 loss to the total loss\n","\n","            total_loss.backward()\n","            optimizer.step()\n","# Evaluate model on training data\n","best_model.eval()\n","with torch.no_grad():\n","    train_outputs = best_model(X1_train_tensor)\n","    train_pred_probs = [output.squeeze().numpy() for output in train_outputs]\n","\n","Y1_train_np = Y1_train_tensor.numpy()\n","\n","\n","task_idx = 0\n","valid_mask = ~np.isnan(Y1_train_np[:, task_idx])\n","y_true = Y1_train_np[valid_mask, task_idx]\n","y_prob = train_pred_probs[task_idx][valid_mask]\n","\n","# Calculate ROC AUC\n","fpr, tpr, _ = roc_curve(y_true, y_prob, pos_label=1)\n","roc_auc = auc(fpr, tpr)\n","\n","# Predict labels\n","y_pred = (y_prob > 0.5).astype(float)\n","\n","# Compute metrics\n","results = model_metrics(y_true, y_pred, y_prob)\n","\n","print('---------------------------------------------')\n","print('Training Results')\n","print(f'ROC AUC: {roc_auc:.3f}')\n","print('Other metrics (Balanced Accuracy, MCC, Accuracy, Precision, Recall, F1):')\n","print(\", \".join([f\"{res:.3f}\" for res in results]))\n","\n","# Save model\n","model_path = \"best_model_single-task.pth\"\n","torch.save({\n","    'model_state_dict': best_model.state_dict(),\n","    'params': best_params,\n","}, model_path)\n","\n","# Save scaler (if applicable)\n","if mode == \"Descriptors\":\n","    scaler_path = \"descriptor_scaler.pkl\"\n","    joblib.dump(scaler, scaler_path)\n","\n","# Download files if using Google Colab\n","try:\n","    from google.colab import files\n","    files.download(model_path)\n","    if mode == \"Descriptors\":\n","        files.download(scaler_path)\n","except ImportError:\n","    print(f\"Files saved locally: {model_path} and (if used) {scaler_path}\")"],"metadata":{"id":"bHD7A4KjAqfc","colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"status":"ok","timestamp":1753820251220,"user_tz":420,"elapsed":22106,"user":{"displayName":"Alexa Canchola","userId":"12486619005608823341"}},"outputId":"a7fa0622-162e-47d6-e33c-7ef91b564348"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["---------------------------------------------\n","Training Results\n","ROC AUC: 0.991\n","Other metrics (Balanced Accuracy, MCC, Accuracy, Precision, Recall, F1):\n","0.991, 0.948, 0.898, 0.948, 0.919, 0.983, 0.950\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_d9308662-1402-4c23-85ff-87cdf4179b70\", \"best_model_multitask.pth\", 241777)"]},"metadata":{}}]},{"cell_type":"code","source":["# %% ============================================================================\n","# Save trained model & hyperparameters\n","# ============================================================================\n","model_path = \"best_model_single-task.pth\"\n","torch.save({\n","    'model_state_dict': best_model.state_dict(),\n","    'params': best_params,\n","    'input_size': X_train_tensor.shape[1],\n","}, model_path)\n","\n","# Initialize scaler_path\n","scaler_path = None\n","\n","# Save scaler (if applicable)\n","if mode == \"Descriptors\":\n","    scaler_path = \"descriptor_scaler.pkl\"\n","    joblib.dump(scaler, scaler_path)\n","\n","# Download files if using Google Colab\n","try:\n","    files.download(model_path)\n","    if mode == \"Descriptors\":\n","        files.download(scaler_path)\n","except ImportError:\n","    print(f\"Files saved locally: {model_path} and (if used) {scaler_path}\")"],"metadata":{"id":"Se8pbP9e9R6i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#  ============================================================================\n","# Use Best Model to get Predictions on the Test Dataset\n","# ============================================================================\n","\n","best_model.eval()  # Set the model to evaluation mode\n","with torch.no_grad():\n","    test_outputs = best_model(X1_test_tensor)\n","    test_pred_probs = torch.stack(test_outputs, dim=1)  # Stack all outputs\n","\n","num_tasks = len(task_names)\n","\n","# Create plot for ROC curve\n","plt.figure(figsize=(5, 4))\n","accuracies = []\n","\n","for task_idx in range(num_tasks):\n","    Y1_test_np = Y1_test.to_numpy()\n","    valid_mask = ~np.isnan(Y1_test_np[:, task_idx])  # Mask for valid labels\n","    valid_true_labels = Y1_test_np[valid_mask, task_idx]\n","    test_pred_probs_task = test_pred_probs[valid_mask, task_idx].numpy()\n","\n","    # Calculate ROC curve\n","    fpr, tpr, _ = roc_curve(valid_true_labels, test_pred_probs_task, pos_label=1)\n","    roc_auc = auc(fpr, tpr)\n","    print('--------------------------------------------------------------------')\n","    print('AUC for ' + task_names[task_idx] + ': ' + str(roc_auc))\n","    print('FPR for ' + task_names[task_idx] + ': ' + str(fpr))\n","    print('TPR for ' + task_names[task_idx] + ': ' + str(tpr))\n","\n","    plt.plot(fpr, tpr, lw=2, label=f'{task_names[task_idx]} (AUC = {roc_auc:.2f})')\n","\n","    # Calculate accuracy for this task\n","    predicted_labels = np.array([1.0 if output > 0.5 else 0.0 for output in test_pred_probs_task])\n","\n","    test_results = model_metrics(valid_true_labels, predicted_labels, test_pred_probs_task)\n","\n","    print('--------------------------------------------------------------------')\n","    print(\"Overall Results for Test Set:\")\n","    print(\"ROC-AUC, Balanced Accuracy, MCC, Accuracy, Precision, Recall, F1:\")\n","    print(\", \".join([f\"{result:.3f}\" for result in test_results]))\n","\n","plt.plot([0, 1], [0, 1], color='red', linestyle='--')  # Plot Random Classifier Line\n","\n","plt.xticks(np.arange(0, 1.1, 0.2), fontsize=12)\n","plt.yticks(np.arange(0, 1.1, 0.2), fontsize=12)\n","plt.xlim([-0.01, 1.01])\n","plt.ylim([-0.01, 1.01])\n","plt.xlabel('False Positive Rate', fontsize=12)\n","plt.ylabel('True Positive Rate', fontsize=12)\n","plt.title('', fontsize=12)\n","plt.grid(True)\n","plt.legend(loc='lower right', fontsize=8.6)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"erTVf7wSBIXP","colab":{"base_uri":"https://localhost:8080/","height":753},"executionInfo":{"status":"ok","timestamp":1753813934256,"user_tz":420,"elapsed":289,"user":{"displayName":"Alexa Canchola","userId":"12486619005608823341"}},"outputId":"4869a04b-07ed-4d36-c418-5caeb912d43a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------\n","AUC for Genotoxicity: 0.658187984496124\n","FPR for Genotoxicity: [0.         0.02325581 0.02325581 0.04651163 0.09302326 0.09302326\n"," 0.13953488 0.13953488 0.18604651 0.18604651 0.25581395 0.25581395\n"," 0.3255814  0.3255814  0.37209302 0.37209302 0.41860465 0.41860465\n"," 0.44186047 0.44186047 0.46511628 0.46511628 0.48837209 0.48837209\n"," 0.53488372 0.53488372 0.62790698 0.62790698 0.6744186  0.72093023\n"," 0.76744186 0.81395349 0.81395349 0.95348837 0.95348837 1.\n"," 1.        ]\n","TPR for Genotoxicity: [0.         0.0625     0.16666667 0.16666667 0.16666667 0.27083333\n"," 0.27083333 0.33333333 0.33333333 0.39583333 0.39583333 0.5625\n"," 0.5625     0.58333333 0.58333333 0.625      0.625      0.66666667\n"," 0.66666667 0.6875     0.6875     0.75       0.75       0.77083333\n"," 0.77083333 0.83333333 0.83333333 0.85416667 0.85416667 0.85416667\n"," 0.85416667 0.85416667 0.91666667 0.91666667 0.97916667 0.97916667\n"," 1.        ]\n","--------------------------------------------------------------------\n","Overall Results for Test Set:\n","ROC-AUC, Balanced Accuracy, MCC, Accuracy, Precision, Recall, F1:\n","0.658, 0.642, 0.292, 0.648, 0.643, 0.750, 0.692\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 500x400 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["# ============================================================================\n","# Generate Applicability Domain Plot for Each Task\n","# ===============================================================================\n","def dropout_uncertainty(model, X, task_idx, num_samples=100):\n","    model.train()  # Set the model in train mode to keep dropout active\n","    predictions = []\n","    for _ in range(num_samples):\n","        output = model(X)[task_idx]\n","        predictions.append(output.detach().cpu().numpy())\n","\n","    predictions = np.array(predictions)  # Shape: (num_samples, n_samples)\n","    mean_predictions = predictions.mean(axis=0)\n","    std_predictions = predictions.std(axis=0)\n","    return mean_predictions.squeeze(), std_predictions.squeeze()\n","\n","n_samples = 50\n","epsilon = 1.5e-2\n","\n","# Containers for predictions per task\n","mean_predictions_train = []\n","std_predictions_train = []\n","mean_predictions_test = []\n","std_predictions_test = []\n","\n","for i in range(len(task_names)):\n","    mean_train, std_train = dropout_uncertainty(best_model, X1_train_tensor, task_idx=i, num_samples=n_samples)\n","    mean_test, std_test = dropout_uncertainty(best_model, X1_test_tensor, task_idx=i, num_samples=n_samples)\n","\n","    mean_predictions_train.append(mean_train)\n","    std_predictions_train.append(std_train)\n","    mean_predictions_test.append(mean_test)\n","    std_predictions_test.append(std_test)\n","\n","all_std_train = np.concatenate(std_predictions_train)\n","uncertainty_threshold = np.percentile(all_std_train, 95)  # 95th percentile threshold\n","\n","X_train_np = X_train_resampled.values\n","X_test_np = X1_test.values\n","\n","# Standardize\n","from sklearn.preprocessing import RobustScaler\n","\n","# Robust scaling\n","scaler = RobustScaler()\n","X_train_scaled = scaler.fit_transform(X_train_np)\n","X_test_scaled = scaler.transform(X_test_np)\n","\n","\n","# PCA\n","pca = PCA(n_components=10)  # Choose appropriate number of components\n","X_train_pca = pca.fit_transform(X_train_scaled)\n","X_test_pca = pca.transform(X_test_scaled)\n","\n","# Compute train centroid\n","centroid = X_train_pca.mean(axis=0)\n","\n","# Compute distances\n","distances_train = np.linalg.norm(X_train_pca - centroid, axis=1)\n","distances_test = np.linalg.norm(X_test_pca - centroid, axis=1)\n","\n","# Close previous figures\n","plt.close('all')\n","\n","fig, ax = plt.subplots(figsize=(8, 7))\n","\n","colors = {'Train': 'blue', 'Test': 'orange'}\n","markers = {'Genotoxicity': 'o'}\n","\n","for i, target_name in enumerate(task_names):\n","    y_true_train = Y1_train_tensor[:, i].numpy()\n","    mask_train = ~np.isnan(y_true_train)\n","    y_true_train = y_true_train[mask_train]\n","    y_predictions_train = np.clip(mean_predictions_train[i][mask_train], epsilon, 1 - epsilon)\n","\n","    residuals_train = y_true_train - y_predictions_train\n","    pearson_train = residuals_train / np.sqrt(y_predictions_train * (1 - y_predictions_train))\n","\n","    y_true_test = Y1_test_tensor[:, i].numpy()\n","    mask_test = ~np.isnan(y_true_test)\n","    y_true_test = y_true_test[mask_test]\n","    y_predictions_test = np.clip(mean_predictions_test[i][mask_test], epsilon, 1 - epsilon)\n","\n","    residuals_test = y_true_test - y_predictions_test\n","    pearson_test = residuals_test / np.sqrt(y_predictions_test * (1 - y_predictions_test))\n","\n","    ax.scatter(distances_train[mask_train], pearson_train, alpha=0.5,\n","               color=colors['Train'], marker=markers[target_name],\n","               label=f'{target_name} (Train)')\n","\n","    ax.scatter(distances_test[mask_test], pearson_test, alpha=0.7,\n","               color=colors['Test'], marker=markers[target_name],\n","               label=f'{target_name} (Test)')\n","\n","\n","# Threshold lines\n","distance_threshold = distances_train.mean() + 3 * distances_train.std()\n","ax.axvline(distance_threshold, color='green', linestyle='--', linewidth=1)\n","ax.axhline(3, color='red', linestyle='--', linewidth=1)\n","ax.axhline(-3, color='red', linestyle='--', linewidth=1)\n","\n","label_fontsize = 16\n","title_fontsize = 18\n","tick_fontsize = 14\n","legend_fontsize = 12\n","\n","ax.set_xlabel('PCA Distance to Training Centroid', fontsize=label_fontsize)\n","ax.set_ylabel(\"Pearson's Residuals\", fontsize=label_fontsize)\n","ax.set_title(\"Applicability Domain via PCA Distance\", fontsize=title_fontsize)\n","\n","ax.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n","\n","ax.legend(fontsize=legend_fontsize)\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"BxLoa3DOBLmc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Make Prediction Based for User Input Compounds!\n","\n","Input individual SMILES strings or a list of SMILES strings to predict toxicity for the trained task.\n","Please note that the above model must be re-trained/re-run to use a different fingerprint/descriptor mode!"],"metadata":{"id":"7SBGhred4XNM"}},{"cell_type":"code","source":["# Upload model file\n","uploaded = files.upload()  # Upload 'best_model_single-task.pth'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":74},"id":"ijEfb8m9hYXZ","executionInfo":{"status":"ok","timestamp":1753820476726,"user_tz":420,"elapsed":4301,"user":{"displayName":"Alexa Canchola","userId":"12486619005608823341"}},"outputId":"595dbd7e-0307-4f71-ba7a-3d85e7c236ea"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-179ce06f-8b19-436d-b517-a72484ec4fb3\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-179ce06f-8b19-436d-b517-a72484ec4fb3\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving best_model_multitask.pth to best_model_multitask (1).pth\n"]}]},{"cell_type":"code","source":["# Load model\n","checkpoint = torch.load(\"best_model_multitask.pth\", map_location=torch.device('cpu'))\n","loaded_model = NeuralNetwork(\n","    input_size=expected_input_size,  # You can hardcode this or extract from params\n","    shared_layer_sizes=[checkpoint['params'][3]],\n","    output_layer_sizes=[1, 1, 1],\n","    specific_layer_sizes=[checkpoint['params'][4], checkpoint['params'][4]]\n",")\n","loaded_model.load_state_dict(checkpoint['model_state_dict'])\n","loaded_model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":575},"id":"WW1fHhtS2HGn","executionInfo":{"status":"error","timestamp":1753820518017,"user_tz":420,"elapsed":48,"user":{"displayName":"Alexa Canchola","userId":"12486619005608823341"}},"outputId":"177627b0-9b5e-4cba-8cc8-193ca03f074f"},"execution_count":null,"outputs":[{"output_type":"error","ename":"UnpicklingError","evalue":"Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy._core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([numpy._core.multiarray.scalar])` or the `torch.serialization.safe_globals([numpy._core.multiarray.scalar])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-51-3889050547.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best_model_multitask.pth\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m loaded_model = NeuralNetwork(\n\u001b[1;32m      4\u001b[0m     \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpected_input_size\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# You can hardcode this or extract from params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mshared_layer_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1522\u001b[0m                         )\n\u001b[1;32m   1523\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1524\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1525\u001b[0m                 return _load(\n\u001b[1;32m   1526\u001b[0m                     \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnpicklingError\u001b[0m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy._core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([numpy._core.multiarray.scalar])` or the `torch.serialization.safe_globals([numpy._core.multiarray.scalar])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."]}]},{"cell_type":"code","source":["def ecig_predict(smiles_input, task_names, trained_model):\n","    if isinstance(smiles_input, str):\n","        smiles_list = [smiles_input]\n","    else:\n","        smiles_list = smiles_input\n","\n","    X_input = np.array([smiles_to_feature(sm, mode=mode) for sm in smiles_list]) # uses fingerprint mode model was originally trained on\n","\n","    if mode == \"Descriptors\":\n","        desc_names = [\"RDKit_\" + desc[0] for desc in Descriptors._descList]\n","        X_input_df = pd.DataFrame(X_input, columns=desc_names)\n","        X_input_df = X_input_df.replace([np.inf, -np.inf], np.nan).fillna(0)\n","        if \"scaler\" not in globals():\n","            raise ValueError(\"Global `scaler` not found. Define and fit it during training on Descriptors.\")\n","        X_scaled = scaler.transform(X_input_df)\n","        X_input_df = pd.DataFrame(X_scaled, columns=X_input_df.columns)\n","    else:\n","        X_input_df = pd.DataFrame(X_input, columns=[f'FP_{i}' for i in range(X_input.shape[1])])\n","\n","    X_tensor = torch.tensor(X_input_df.values, dtype=torch.float32)\n","\n","    trained_model.eval()\n","    with torch.no_grad():\n","        outputs = trained_model(X_tensor)\n","\n","    if isinstance(outputs, list):\n","        outputs = outputs[0]\n","\n","    probabilities = outputs.squeeze().numpy()\n","    probabilities = np.atleast_1d(probabilities)\n","\n","    print(f\"\\n=== Prediction Results ===\")\n","    for i, sm in enumerate(smiles_list):\n","        prob = probabilities[i]\n","        pred = 1 if prob > 0.5 else 0\n","        interpretation = f\"This model predicts that this compound is **Toxic** for {task_names}\" if pred == 1 else f\"This model predicts that this compound is **Non-Toxic** for {task_names}\"\n","        print(f\"\\nSMILES: {sm}\")\n","        print(f\"Prediction: {pred}\")\n","        print (f\"{interpretation}\")\n","        print(f\"Prediction Confidence: {prob:.2%}\")\n","\n","\n","\n","# === INPUT SMILES HERE  ===\n","smiles_input = [\"CC(=O)C1=CC=CC=C1\"]\n","\n","# === MAKE PREDICTION  ===\n","ecig_predict(smiles_input, task_names, trained_model=loaded_model) # Change to 'best_model' if you re-trained model"],"metadata":{"id":"zsFDliOd1mrB"},"execution_count":null,"outputs":[]}]}